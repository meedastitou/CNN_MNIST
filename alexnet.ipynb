{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1p33X-IT4wpYdKVwwrdRjXNBEdCXodPZT",
      "authorship_tag": "ABX9TyOQVtp4KyWzGuAknsdnIxLa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meedastitou/CNN_MNIST/blob/main/alexnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps6bNZ3ocl6I",
        "outputId": "0bd9ce1c-5c37-4249-f3f4-ff34cf141565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting idx2numpy\n",
            "  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from idx2numpy) (1.26.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from idx2numpy) (1.16.0)\n",
            "Building wheels for collected packages: idx2numpy\n",
            "  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7904 sha256=2d2f37be0e9cdb33f09dce388cbbb72ae2d9a573245ee04d5862b2a6af1efc3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/f4/e7/643fc5f932ec2ff92997f43f007660feb23f948aa8486f1107\n",
            "Successfully built idx2numpy\n",
            "Installing collected packages: idx2numpy\n",
            "Successfully installed idx2numpy-1.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install idx2numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import idx2numpy\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "metadata": {
        "id": "3zp7xFaccrNB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "6pYN_XO1dA42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_path = \"/content/drive/MyDrive/Colab Notebooks/train-images.idx3-ubyte\"\n",
        "train_labels_path = \"/content/drive/MyDrive/Colab Notebooks/train-labels.idx1-ubyte\"\n",
        "test_images_path = \"/content/drive/MyDrive/Colab Notebooks/t10k-images.idx3-ubyte\"\n",
        "test_labels_path = \"/content/drive/MyDrive/Colab Notebooks/t10k-labels.idx1-ubyte\""
      ],
      "metadata": {
        "id": "Rt6nPs2ae-g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data into NumPy arrays\n",
        "train_images = idx2numpy.convert_from_file(train_images_path)\n",
        "train_labels = idx2numpy.convert_from_file(train_labels_path)\n",
        "test_images = idx2numpy.convert_from_file(test_images_path)\n",
        "test_labels = idx2numpy.convert_from_file(test_labels_path)"
      ],
      "metadata": {
        "id": "HuKAOTR_fATc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUK-Qm_WfG_h",
        "outputId": "33c08107-9eaa-4d3e-a802-1dea879fce84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify dimensions\n",
        "print(f\"Train Images: {train_images.shape}, Train Labels: {train_labels.shape}\")\n",
        "print(f\"Test Images: {test_images.shape}, Test Labels: {test_labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4Si7JLbfKM-",
        "outputId": "4f2675cf-791f-4b6b-b91b-521949ea47ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images: (60000, 28, 28), Train Labels: (60000,)\n",
            "Test Images: (10000, 28, 28), Test Labels: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# customize my data for pytorch\n",
        "class mnist_data(Dataset):\n",
        "  def __init__(self, images, labels, transform):\n",
        "    self.images = images\n",
        "    self.labels = labels\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__ (self):\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, index) :\n",
        "    image = self.images[index]\n",
        "    label = self.labels[index]\n",
        "    image = self.transform(image)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "1RuFqqwjfPer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# information about alexnet in pytorch #"
      ],
      "metadata": {
        "id": "fgem0C41f1Pt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All pre-trained models expect **input images normalized** in the same way, i.e. **mini-batches of 3-channel** RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be l**oaded in to a range of [0, 1]** and **then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].**\n"
      ],
      "metadata": {
        "id": "aieR3HgogZTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "QZv4gfy8fZP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = mnist_data(train_images, train_labels, transform)\n",
        "test_dataset = mnist_data(test_images, test_labels, transform)\n",
        "\n",
        "\n",
        "# create dataloader for batching\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "72qwfg-EglSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)"
      ],
      "metadata": {
        "id": "JA3tPJmGhT9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b8559b-9884-405d-e8b0-fcf92991dcf5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:02<00:00, 96.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nux4h3dsjfeB",
        "outputId": "08218b71-06c1-480a-9fc6-3fc95d788f36"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xg7uOQ7jMWw",
        "outputId": "6406bfcc-9634-4084-e20b-4e28a4b2bac5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (4): ReLU(inplace=True)\n",
              "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (7): ReLU(inplace=True)\n",
              "  (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (9): ReLU(inplace=True)\n",
              "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (11): ReLU(inplace=True)\n",
              "  (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.features[0]"
      ],
      "metadata": {
        "id": "MXbEpTiphb7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c5b1dd-99a9-4a04-abe8-d2167991ff02"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i will change the number of chanel to **gray** ( 3 to 1)"
      ],
      "metadata": {
        "id": "pOHUeslbi84x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.features[0] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))"
      ],
      "metadata": {
        "id": "WCyygfm4iKjd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "i will change the **number of classes** (output) to 10"
      ],
      "metadata": {
        "id": "FQyoJAGnjxEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo2pHXIijaX8",
        "outputId": "3f7450e9-74b8-4808-baaa-928a4e80f9d7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Dropout(p=0.5, inplace=False)\n",
              "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): Dropout(p=0.5, inplace=False)\n",
              "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (5): ReLU(inplace=True)\n",
              "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdD5MelFjobd",
        "outputId": "c6ddc781-abaa-4b98-ca26-6fc22fba59c1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=4096, out_features=1000, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier[6] = nn.Linear(in_features=4096, out_features=10, bias=True)"
      ],
      "metadata": {
        "id": "ilXX-eKkjkpY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4MQN3SwjvQT",
        "outputId": "9860206a-4d0e-4f32-e3de-d817ed069b5b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "Fdeuqr7CmlV0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.size()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDpbOabZmrG1",
        "outputId": "8adc4595-4442-41fe-de1c-28fb0bf5bef4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.0.weight: torch.Size([64, 1, 11, 11])\n",
            "features.0.bias: torch.Size([64])\n",
            "features.3.weight: torch.Size([192, 64, 5, 5])\n",
            "features.3.bias: torch.Size([192])\n",
            "features.6.weight: torch.Size([384, 192, 3, 3])\n",
            "features.6.bias: torch.Size([384])\n",
            "features.8.weight: torch.Size([256, 384, 3, 3])\n",
            "features.8.bias: torch.Size([256])\n",
            "features.10.weight: torch.Size([256, 256, 3, 3])\n",
            "features.10.bias: torch.Size([256])\n",
            "classifier.1.weight: torch.Size([4096, 9216])\n",
            "classifier.1.bias: torch.Size([4096])\n",
            "classifier.4.weight: torch.Size([4096, 4096])\n",
            "classifier.4.bias: torch.Size([4096])\n",
            "classifier.6.weight: torch.Size([10, 4096])\n",
            "classifier.6.bias: torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraînement du modèle\n",
        "num_epochs = 5\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "diGqj3GCnskd"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "niaQemU2odxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluation\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calcul des métriques\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "i74YtWEkomaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for plotting\n",
        "metrics = ['Accuracy', 'F1 Score']\n",
        "values = [accuracy, f1]\n",
        "\n",
        "# Create a bar chart\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(metrics, values, color=['blue', 'orange'])\n",
        "plt.ylim(0, 1)  # Set y-axis limits from 0 to 1\n",
        "plt.title('Model Performance Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.axhline(y=0.90, color='red', linestyle='--', label='90% Threshold')  # Optional threshold line\n",
        "plt.legend()\n",
        "plt.grid(axis='y')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B_XG-n3EpwRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CISg_LbsqOva"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}